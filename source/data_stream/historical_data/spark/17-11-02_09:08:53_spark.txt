17/11/02 09:08:53 INFO SparkContext: Running Spark version 2.2.0
17/11/02 09:08:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/02 09:08:53 INFO SparkContext: Submitted application: W2V
17/11/02 09:08:53 INFO SecurityManager: Changing view acls to: centos
17/11/02 09:08:53 INFO SecurityManager: Changing modify acls to: centos
17/11/02 09:08:53 INFO SecurityManager: Changing view acls groups to: 
17/11/02 09:08:53 INFO SecurityManager: Changing modify acls groups to: 
17/11/02 09:08:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(centos); groups with view permissions: Set(); users  with modify permissions: Set(centos); groups with modify permissions: Set()
17/11/02 09:08:53 INFO Utils: Successfully started service 'sparkDriver' on port 42003.
17/11/02 09:08:53 INFO SparkEnv: Registering MapOutputTracker
17/11/02 09:08:53 INFO SparkEnv: Registering BlockManagerMaster
17/11/02 09:08:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/11/02 09:08:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/11/02 09:08:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c93c791b-b9a7-4e87-aa04-77aee01c49e4
17/11/02 09:08:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/11/02 09:08:53 INFO SparkEnv: Registering OutputCommitCoordinator
17/11/02 09:08:53 INFO log: Logging initialized @1655ms
17/11/02 09:08:54 INFO Server: jetty-9.3.z-SNAPSHOT
17/11/02 09:08:54 INFO Server: Started @1720ms
17/11/02 09:08:54 INFO AbstractConnector: Started ServerConnector@262745b0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/11/02 09:08:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@ecf9049{/jobs,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@70e29e14{/jobs/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5a4bef8{/jobs/job,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/jobs/job/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5d8445d7{/stages,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@384fc774{/stages/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@71e9a896{/stages/stage,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@15bcf458{/stages/stage/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@43c67247{/stages/pool,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@726386ed{/stages/pool/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@14bb2297{/storage,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@797501a{/storage/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/storage/rdd,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/storage/rdd/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@30c31dd7{/environment,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@596df867{/environment/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/executors,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/executors/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@615f972{/executors/threadDump,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@73393584{/executors/threadDump/json,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1827a871{/static,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@82c57b3{/,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@600b0b7{/api,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77b7ffa4{/jobs/job/kill,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@402f80f5{/stages/stage/kill,null,AVAILABLE,@Spark}
17/11/02 09:08:54 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.0.21:4040
17/11/02 09:08:54 INFO SparkContext: Added JAR file:/home/centos/sparksample_ssw2/target/scala-2.10/spark-sample_2.10-1.0.jar at spark://10.0.0.21:42003/jars/spark-sample_2.10-1.0.jar with timestamp 1509588534116
17/11/02 09:08:54 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://ssw1-sea-master-0.novalocal:7077...
17/11/02 09:08:54 INFO TransportClientFactory: Successfully created connection to ssw1-sea-master-0.novalocal/10.0.0.21:7077 after 24 ms (0 ms spent in bootstraps)
17/11/02 09:08:54 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20171102090854-0011
17/11/02 09:08:54 INFO TaskSchedulerImpl: Starting speculative execution thread
17/11/02 09:08:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171102090854-0011/0 on worker-20171101033531-10.0.0.9-45482 (10.0.0.9:45482) with 4 cores
17/11/02 09:08:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20171102090854-0011/0 on hostPort 10.0.0.9:45482 with 4 cores, 1024.0 MB RAM
17/11/02 09:08:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171102090854-0011/1 on worker-20171101033533-10.0.0.24-41629 (10.0.0.24:41629) with 4 cores
17/11/02 09:08:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20171102090854-0011/1 on hostPort 10.0.0.24:41629 with 4 cores, 1024.0 MB RAM
17/11/02 09:08:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34923.
17/11/02 09:08:54 INFO NettyBlockTransferService: Server created on 10.0.0.21:34923
17/11/02 09:08:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/11/02 09:08:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.0.21, 34923, None)
17/11/02 09:08:54 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.0.21:34923 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.21, 34923, None)
17/11/02 09:08:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.0.21, 34923, None)
17/11/02 09:08:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171102090854-0011/1 is now RUNNING
17/11/02 09:08:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171102090854-0011/0 is now RUNNING
17/11/02 09:08:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.0.21, 34923, None)
17/11/02 09:08:54 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7ed9ae94{/metrics/json,null,AVAILABLE,@Spark}
17/11/02 09:08:55 INFO EventLoggingListener: Logging events to hdfs:///tmp/spark-events/app-20171102090854-0011
17/11/02 09:08:55 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/11/02 09:08:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.0.9:59898) with ID 0
17/11/02 09:08:55 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.0.9:40678 with 366.3 MB RAM, BlockManagerId(0, 10.0.0.9, 40678, None)
17/11/02 09:08:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.0.24:49436) with ID 1
17/11/02 09:08:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 240.1 KB, free 366.1 MB)
17/11/02 09:08:55 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.0.24:33644 with 366.3 MB RAM, BlockManagerId(1, 10.0.0.24, 33644, None)
17/11/02 09:08:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.5 KB, free 366.0 MB)
17/11/02 09:08:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.0.21:34923 (size: 23.5 KB, free: 366.3 MB)
17/11/02 09:08:55 INFO SparkContext: Created broadcast 0 from textFile at W2V1.scala:7
17/11/02 09:08:56 INFO FileInputFormat: Total input paths to process : 1
17/11/02 09:08:56 INFO SparkContext: Starting job: collect at Word2Vec.scala:196
17/11/02 09:08:56 INFO DAGScheduler: Registering RDD 4 (map at Word2Vec.scala:187)
17/11/02 09:08:56 INFO DAGScheduler: Got job 0 (collect at Word2Vec.scala:196) with 12 output partitions
17/11/02 09:08:56 INFO DAGScheduler: Final stage: ResultStage 1 (collect at Word2Vec.scala:196)
17/11/02 09:08:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/11/02 09:08:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/11/02 09:08:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at map at Word2Vec.scala:187), which has no missing parents
17/11/02 09:08:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 366.0 MB)
17/11/02 09:08:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 366.0 MB)
17/11/02 09:08:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.0.21:34923 (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:08:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/11/02 09:08:56 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at map at Word2Vec.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
17/11/02 09:08:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 12 tasks
17/11/02 09:08:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.0.0.24, executor 1, partition 0, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.0.0.9, executor 0, partition 1, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 10.0.0.24, executor 1, partition 2, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 10.0.0.9, executor 0, partition 3, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 10.0.0.24, executor 1, partition 4, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 10.0.0.9, executor 0, partition 5, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 10.0.0.24, executor 1, partition 6, ANY, 4874 bytes)
17/11/02 09:08:56 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 10.0.0.9, executor 0, partition 7, ANY, 4874 bytes)
17/11/02 09:08:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.0.9:40678 (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:08:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.0.24:33644 (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:08:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.0.9:40678 (size: 23.5 KB, free: 366.3 MB)
17/11/02 09:08:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.0.24:33644 (size: 23.5 KB, free: 366.3 MB)
17/11/02 09:09:05 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 10.0.0.9, executor 0, partition 8, ANY, 4874 bytes)
17/11/02 09:09:05 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 10.0.0.9, executor 0, partition 9, ANY, 4874 bytes)
17/11/02 09:09:05 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 8972 ms on 10.0.0.9 (executor 0) (1/12)
17/11/02 09:09:05 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 8978 ms on 10.0.0.9 (executor 0) (2/12)
17/11/02 09:09:05 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 10.0.0.9, executor 0, partition 10, ANY, 4874 bytes)
17/11/02 09:09:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9014 ms on 10.0.0.9 (executor 0) (3/12)
17/11/02 09:09:05 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 10.0.0.9, executor 0, partition 11, ANY, 4874 bytes)
17/11/02 09:09:05 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 9064 ms on 10.0.0.9 (executor 0) (4/12)
17/11/02 09:09:06 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 9846 ms on 10.0.0.24 (executor 1) (5/12)
17/11/02 09:09:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9876 ms on 10.0.0.24 (executor 1) (6/12)
17/11/02 09:09:06 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 9902 ms on 10.0.0.24 (executor 1) (7/12)
17/11/02 09:09:06 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 9945 ms on 10.0.0.24 (executor 1) (8/12)
17/11/02 09:09:06 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 1097 ms on 10.0.0.9 (executor 0) (9/12)
17/11/02 09:09:10 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 4985 ms on 10.0.0.9 (executor 0) (10/12)
17/11/02 09:09:11 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 5813 ms on 10.0.0.9 (executor 0) (11/12)
17/11/02 09:09:11 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 5770 ms on 10.0.0.9 (executor 0) (12/12)
17/11/02 09:09:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/11/02 09:09:11 INFO DAGScheduler: ShuffleMapStage 0 (map at Word2Vec.scala:187) finished in 14.802 s
17/11/02 09:09:11 INFO DAGScheduler: looking for newly runnable stages
17/11/02 09:09:11 INFO DAGScheduler: running: Set()
17/11/02 09:09:11 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/11/02 09:09:11 INFO DAGScheduler: failed: Set()
17/11/02 09:09:11 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Word2Vec.scala:190), which has no missing parents
17/11/02 09:09:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 366.0 MB)
17/11/02 09:09:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.0 MB)
17/11/02 09:09:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.0.21:34923 (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/11/02 09:09:11 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Word2Vec.scala:190) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
17/11/02 09:09:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 12 tasks
17/11/02 09:09:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 12, 10.0.0.9, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 13, 10.0.0.24, executor 1, partition 1, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 14, 10.0.0.9, executor 0, partition 2, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 15, 10.0.0.24, executor 1, partition 3, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 16, 10.0.0.9, executor 0, partition 4, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 17, 10.0.0.24, executor 1, partition 5, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 18, 10.0.0.9, executor 0, partition 6, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 19, 10.0.0.24, executor 1, partition 7, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.0.9:40678 (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.0.24:33644 (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.0.9:59898
17/11/02 09:09:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 211 bytes
17/11/02 09:09:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.0.24:49436
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_15 in memory on 10.0.0.24:33644 (size: 4.4 MB, free: 361.9 MB)
17/11/02 09:09:13 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 20, 10.0.0.24, executor 1, partition 8, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:13 INFO TransportClientFactory: Successfully created connection to /10.0.0.24:33644 after 3 ms (0 ms spent in bootstraps)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_19 in memory on 10.0.0.24:33644 (size: 4.4 MB, free: 357.5 MB)
17/11/02 09:09:13 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 21, 10.0.0.24, executor 1, partition 9, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_16 in memory on 10.0.0.9:40678 (size: 4.3 MB, free: 361.9 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_12 in memory on 10.0.0.9:40678 (size: 4.4 MB, free: 357.5 MB)
17/11/02 09:09:13 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 22, 10.0.0.9, executor 0, partition 10, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:13 INFO TransportClientFactory: Successfully created connection to /10.0.0.9:40678 after 3 ms (0 ms spent in bootstraps)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_13 in memory on 10.0.0.24:33644 (size: 4.4 MB, free: 353.1 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_17 in memory on 10.0.0.24:33644 (size: 4.4 MB, free: 348.7 MB)
17/11/02 09:09:13 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 23, 10.0.0.9, executor 0, partition 11, NODE_LOCAL, 4625 bytes)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_18 in memory on 10.0.0.9:40678 (size: 4.4 MB, free: 353.1 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_14 in memory on 10.0.0.9:40678 (size: 4.4 MB, free: 348.7 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 19) in 2151 ms on 10.0.0.24 (executor 1) (1/12)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 12) in 2166 ms on 10.0.0.9 (executor 0) (2/12)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 15) in 2162 ms on 10.0.0.24 (executor 1) (3/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_12 on 10.0.0.9:40678 in memory (size: 4.4 MB, free: 353.1 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 16) in 2165 ms on 10.0.0.9 (executor 0) (4/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_19 on 10.0.0.24:33644 in memory (size: 4.4 MB, free: 353.1 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_16 on 10.0.0.9:40678 in memory (size: 4.3 MB, free: 357.5 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_15 on 10.0.0.24:33644 in memory (size: 4.4 MB, free: 357.5 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 18) in 2333 ms on 10.0.0.9 (executor 0) (5/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_18 on 10.0.0.9:40678 in memory (size: 4.4 MB, free: 361.9 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 17) in 2349 ms on 10.0.0.24 (executor 1) (6/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_17 on 10.0.0.24:33644 in memory (size: 4.4 MB, free: 361.9 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 13) in 2363 ms on 10.0.0.24 (executor 1) (7/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_13 on 10.0.0.24:33644 in memory (size: 4.4 MB, free: 366.3 MB)
17/11/02 09:09:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 14) in 2392 ms on 10.0.0.9 (executor 0) (8/12)
17/11/02 09:09:13 INFO BlockManagerInfo: Removed taskresult_14 on 10.0.0.9:40678 in memory (size: 4.4 MB, free: 366.3 MB)
17/11/02 09:09:13 INFO BlockManagerInfo: Added taskresult_23 in memory on 10.0.0.9:40678 (size: 4.4 MB, free: 361.9 MB)
17/11/02 09:09:14 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 23) in 868 ms on 10.0.0.9 (executor 0) (9/12)
17/11/02 09:09:14 INFO BlockManagerInfo: Added taskresult_20 in memory on 10.0.0.24:33644 (size: 4.5 MB, free: 361.8 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed taskresult_23 on 10.0.0.9:40678 in memory (size: 4.4 MB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Added taskresult_21 in memory on 10.0.0.24:33644 (size: 4.3 MB, free: 357.5 MB)
17/11/02 09:09:14 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 20) in 1068 ms on 10.0.0.24 (executor 1) (10/12)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed taskresult_20 on 10.0.0.24:33644 in memory (size: 4.5 MB, free: 361.9 MB)
17/11/02 09:09:14 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 21) in 1027 ms on 10.0.0.24 (executor 1) (11/12)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed taskresult_21 on 10.0.0.24:33644 in memory (size: 4.3 MB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Added taskresult_22 in memory on 10.0.0.9:40678 (size: 4.4 MB, free: 361.9 MB)
17/11/02 09:09:14 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 22) in 1242 ms on 10.0.0.9 (executor 0) (12/12)
17/11/02 09:09:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/11/02 09:09:14 INFO DAGScheduler: ResultStage 1 (collect at Word2Vec.scala:196) finished in 3.139 s
17/11/02 09:09:14 INFO BlockManagerInfo: Removed taskresult_22 on 10.0.0.9:40678 in memory (size: 4.4 MB, free: 366.3 MB)
17/11/02 09:09:14 INFO DAGScheduler: Job 0 finished: collect at Word2Vec.scala:196, took 18.321052 s
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.0.9:40678 in memory (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.0.24:33644 in memory (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.0.21:34923 in memory (size: 2.6 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.0.9:40678 in memory (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.0.24:33644 in memory (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.0.21:34923 in memory (size: 2.8 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO ContextCleaner: Cleaned shuffle 0
17/11/02 09:09:14 INFO Word2Vec: vocabSize = 130350, trainWordsCount = 19271118
17/11/02 09:09:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.9 KB, free 366.0 MB)
17/11/02 09:09:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.0 MB)
17/11/02 09:09:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.0.21:34923 (size: 4.0 KB, free: 366.3 MB)
17/11/02 09:09:14 INFO SparkContext: Created broadcast 3 from broadcast at Word2Vec.scala:315
17/11/02 09:09:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.3 MB, free 303.8 MB)
17/11/02 09:09:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.0 MB, free 299.8 MB)
17/11/02 09:09:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 362.3 MB)
17/11/02 09:09:15 INFO MemoryStore: Block broadcast_4_piece1 stored as bytes in memory (estimated size 4.0 MB, free 295.8 MB)
17/11/02 09:09:15 INFO BlockManagerInfo: Added broadcast_4_piece1 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 358.3 MB)
17/11/02 09:09:15 INFO SparkContext: Created broadcast 4 from broadcast at Word2Vec.scala:316
17/11/02 09:09:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 MB, free 279.7 MB)
17/11/02 09:09:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.0 MB, free 275.7 MB)
17/11/02 09:09:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 354.3 MB)
17/11/02 09:09:15 INFO MemoryStore: Block broadcast_5_piece1 stored as bytes in memory (estimated size 216.0 KB, free 275.5 MB)
17/11/02 09:09:15 INFO BlockManagerInfo: Added broadcast_5_piece1 in memory on 10.0.0.21:34923 (size: 216.0 KB, free: 354.1 MB)
17/11/02 09:09:15 INFO SparkContext: Created broadcast 5 from broadcast at Word2Vec.scala:317
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 49.7 MB, free 225.7 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.0 MB, free 221.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 350.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece1 stored as bytes in memory (estimated size 4.0 MB, free 217.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece1 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 346.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece2 stored as bytes in memory (estimated size 4.0 MB, free 213.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece2 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 342.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece3 stored as bytes in memory (estimated size 4.0 MB, free 209.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece3 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 338.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece4 stored as bytes in memory (estimated size 4.0 MB, free 205.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece4 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 334.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece5 stored as bytes in memory (estimated size 4.0 MB, free 201.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece5 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 330.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece6 stored as bytes in memory (estimated size 4.0 MB, free 197.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece6 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 326.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece7 stored as bytes in memory (estimated size 4.0 MB, free 193.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece7 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 322.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece8 stored as bytes in memory (estimated size 4.0 MB, free 189.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece8 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 318.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece9 stored as bytes in memory (estimated size 4.0 MB, free 185.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece9 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 314.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece10 stored as bytes in memory (estimated size 4.0 MB, free 181.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece10 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 310.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece11 stored as bytes in memory (estimated size 4.0 MB, free 177.7 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece11 in memory on 10.0.0.21:34923 (size: 4.0 MB, free: 306.1 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_6_piece12 stored as bytes in memory (estimated size 1798.7 KB, free 176.0 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_6_piece12 in memory on 10.0.0.21:34923 (size: 1798.7 KB, free: 304.3 MB)
17/11/02 09:09:16 INFO SparkContext: Created broadcast 6 from broadcast at Word2Vec.scala:359
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 49.7 MB, free 126.2 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 248.7 KB, free 126.0 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.0.21:34923 (size: 248.7 KB, free: 304.1 MB)
17/11/02 09:09:16 INFO SparkContext: Created broadcast 7 from broadcast at Word2Vec.scala:360
17/11/02 09:09:16 INFO SparkContext: Starting job: collect at Word2Vec.scala:438
17/11/02 09:09:16 INFO DAGScheduler: Registering RDD 9 (repartition at Word2Vec.scala:344)
17/11/02 09:09:16 INFO DAGScheduler: Registering RDD 13 (mapPartitionsWithIndex at Word2Vec.scala:361)
17/11/02 09:09:16 INFO DAGScheduler: Got job 1 (collect at Word2Vec.scala:438) with 1 output partitions
17/11/02 09:09:16 INFO DAGScheduler: Final stage: ResultStage 4 (collect at Word2Vec.scala:438)
17/11/02 09:09:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/11/02 09:09:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/11/02 09:09:16 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[9] at repartition at Word2Vec.scala:344), which has no missing parents
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 126.0 MB)
17/11/02 09:09:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KB, free 126.0 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.0.21:34923 (size: 3.3 KB, free: 304.1 MB)
17/11/02 09:09:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
17/11/02 09:09:16 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[9] at repartition at Word2Vec.scala:344) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
17/11/02 09:09:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 12 tasks
17/11/02 09:09:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 24, 10.0.0.9, executor 0, partition 0, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 25, 10.0.0.24, executor 1, partition 1, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 26, 10.0.0.9, executor 0, partition 2, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 27, 10.0.0.24, executor 1, partition 3, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 28, 10.0.0.9, executor 0, partition 4, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 29, 10.0.0.24, executor 1, partition 5, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 30, 10.0.0.9, executor 0, partition 6, ANY, 4874 bytes)
17/11/02 09:09:16 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 31, 10.0.0.24, executor 1, partition 7, ANY, 4874 bytes)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.0.24:33644 (size: 3.3 KB, free: 366.3 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.0.9:40678 (size: 3.3 KB, free: 366.3 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_5_piece1 in memory on 10.0.0.24:33644 (size: 216.0 KB, free: 366.1 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 362.1 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.0.9:40678 (size: 4.0 MB, free: 362.3 MB)
17/11/02 09:09:16 INFO BlockManagerInfo: Added broadcast_5_piece1 in memory on 10.0.0.9:40678 (size: 216.0 KB, free: 362.1 MB)
17/11/02 09:09:19 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 32, 10.0.0.9, executor 0, partition 8, ANY, 4874 bytes)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 26) in 2889 ms on 10.0.0.9 (executor 0) (1/12)
17/11/02 09:09:19 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 33, 10.0.0.9, executor 0, partition 9, ANY, 4874 bytes)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 30) in 3066 ms on 10.0.0.9 (executor 0) (2/12)
17/11/02 09:09:19 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 34, 10.0.0.9, executor 0, partition 10, ANY, 4874 bytes)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 28) in 3077 ms on 10.0.0.9 (executor 0) (3/12)
17/11/02 09:09:19 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 35, 10.0.0.9, executor 0, partition 11, ANY, 4874 bytes)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 24) in 3163 ms on 10.0.0.9 (executor 0) (4/12)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 31) in 3221 ms on 10.0.0.24 (executor 1) (5/12)
17/11/02 09:09:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 25) in 3324 ms on 10.0.0.24 (executor 1) (6/12)
17/11/02 09:09:20 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 29) in 3430 ms on 10.0.0.24 (executor 1) (7/12)
17/11/02 09:09:20 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 27) in 3500 ms on 10.0.0.24 (executor 1) (8/12)
17/11/02 09:09:20 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 35) in 450 ms on 10.0.0.9 (executor 0) (9/12)
17/11/02 09:09:21 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 32) in 2267 ms on 10.0.0.9 (executor 0) (10/12)
17/11/02 09:09:21 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 33) in 2238 ms on 10.0.0.9 (executor 0) (11/12)
17/11/02 09:09:21 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 34) in 2282 ms on 10.0.0.9 (executor 0) (12/12)
17/11/02 09:09:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/11/02 09:09:21 INFO DAGScheduler: ShuffleMapStage 2 (repartition at Word2Vec.scala:344) finished in 5.352 s
17/11/02 09:09:21 INFO DAGScheduler: looking for newly runnable stages
17/11/02 09:09:21 INFO DAGScheduler: running: Set()
17/11/02 09:09:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
17/11/02 09:09:21 INFO DAGScheduler: failed: Set()
17/11/02 09:09:21 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at mapPartitionsWithIndex at Word2Vec.scala:361), which has no missing parents
17/11/02 09:09:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 126.0 MB)
17/11/02 09:09:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.4 KB, free 126.0 MB)
17/11/02 09:09:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.0.21:34923 (size: 3.4 KB, free: 304.1 MB)
17/11/02 09:09:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
17/11/02 09:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at mapPartitionsWithIndex at Word2Vec.scala:361) (first 15 tasks are for partitions Vector(0))
17/11/02 09:09:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/11/02 09:09:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 36, 10.0.0.24, executor 1, partition 0, NODE_LOCAL, 4890 bytes)
17/11/02 09:09:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.0.24:33644 (size: 3.4 KB, free: 362.1 MB)
17/11/02 09:09:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.0.24:49436
17/11/02 09:09:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 179 bytes
17/11/02 09:09:24 INFO BlockManagerInfo: Added rdd_12_0 in memory on 10.0.0.24:33644 (size: 144.9 MB, free: 217.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece9 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 213.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece3 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 209.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece7 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 205.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece10 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 201.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece8 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 197.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece11 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 193.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 189.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece1 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 185.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece4 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 181.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece6 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 177.2 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece12 in memory on 10.0.0.24:33644 (size: 1798.7 KB, free: 175.4 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece2 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 171.4 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_6_piece5 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 167.4 MB)
17/11/02 09:09:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.0.24:33644 (size: 248.7 KB, free: 167.2 MB)
17/11/02 09:09:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 163.2 MB)
17/11/02 09:09:25 INFO BlockManagerInfo: Added broadcast_4_piece1 in memory on 10.0.0.24:33644 (size: 4.0 MB, free: 159.2 MB)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_0_piece0 on disk on 10.0.0.24:33644 (current size: 23.5 KB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_8_piece0 on disk on 10.0.0.24:33644 (current size: 3.3 KB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_5_piece0 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_5_piece1 on disk on 10.0.0.24:33644 (current size: 216.0 KB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_9_piece0 on disk on 10.0.0.24:33644 (current size: 3.4 KB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece9 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece3 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece7 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece10 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece8 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece11 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece0 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Updated broadcast_6_piece1 on disk on 10.0.0.24:33644 (current size: 4.0 MB, original size: 0.0 B)
17/11/02 09:09:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.0.24:33644 (size: 4.0 KB, free: 195.4 MB)
17/11/02 09:13:04 INFO BlockManagerInfo: Removed rdd_12_0 on 10.0.0.24:33644 in memory (size: 144.9 MB, free: 340.3 MB)
17/11/02 09:13:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 36) in 223678 ms on 10.0.0.24 (executor 1) (1/1)
17/11/02 09:13:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/11/02 09:13:05 INFO DAGScheduler: ShuffleMapStage 3 (mapPartitionsWithIndex at Word2Vec.scala:361) finished in 223.679 s
17/11/02 09:13:05 INFO DAGScheduler: looking for newly runnable stages
17/11/02 09:13:05 INFO DAGScheduler: running: Set()
17/11/02 09:13:05 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/11/02 09:13:05 INFO DAGScheduler: failed: Set()
17/11/02 09:13:05 INFO DAGScheduler: Submitting ResultStage 4 (ShuffledRDD[14] at reduceByKey at Word2Vec.scala:435), which has no missing parents
17/11/02 09:13:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.4 KB, free 126.0 MB)
17/11/02 09:13:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 126.0 MB)
17/11/02 09:13:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.0.21:34923 (size: 2.4 KB, free: 304.1 MB)
17/11/02 09:13:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
17/11/02 09:13:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (ShuffledRDD[14] at reduceByKey at Word2Vec.scala:435) (first 15 tasks are for partitions Vector(0))
17/11/02 09:13:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/11/02 09:13:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 37, 10.0.0.24, executor 1, partition 0, NODE_LOCAL, 4625 bytes)
17/11/02 09:13:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.0.24:33644 (size: 2.4 KB, free: 340.3 MB)
17/11/02 09:13:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.0.24:49436
17/11/02 09:13:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 137 bytes
17/11/02 09:13:07 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 37, 10.0.0.24, executor 1): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:239)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:403)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/11/02 09:13:07 ERROR TaskSetManager: Task 0 in stage 4.0 failed 1 times; aborting job
17/11/02 09:13:07 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/11/02 09:13:07 INFO TaskSchedulerImpl: Cancelling stage 4
17/11/02 09:13:07 INFO DAGScheduler: ResultStage 4 (collect at Word2Vec.scala:438) failed in 2.060 s due to Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 37, 10.0.0.24, executor 1): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:239)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:403)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
17/11/02 09:13:07 INFO DAGScheduler: Job 1 failed: collect at Word2Vec.scala:438, took 231.148133 s
17/11/02 09:13:07 INFO TorrentBroadcast: Destroying Broadcast(3) (from destroy at Word2Vec.scala:321)
17/11/02 09:13:07 INFO TorrentBroadcast: Destroying Broadcast(4) (from destroy at Word2Vec.scala:322)
17/11/02 09:13:07 INFO TorrentBroadcast: Destroying Broadcast(5) (from destroy at Word2Vec.scala:323)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.0.21:34923 in memory (size: 4.0 KB, free: 304.1 MB)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_5_piece1 on 10.0.0.9:40678 in memory (size: 216.0 KB, free: 362.3 MB)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.0.21:34923 in memory (size: 4.0 MB, free: 308.1 MB)
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 37, 10.0.0.24, executor 1): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:239)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:403)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:935)
	at org.apache.spark.mllib.feature.Word2Vec$$anonfun$doFit$1.apply$mcVI$sp(Word2Vec.scala:438)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.mllib.feature.Word2Vec.doFit(Word2Vec.scala:358)
	at org.apache.spark.mllib.feature.Word2Vec.fit(Word2Vec.scala:319)
	at W2V1$.main(W2V1.scala:9)
	at W2V1.main(W2V1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)
	at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)
	at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)
	at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:239)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303)
	at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)
	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:403)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_5_piece1 on 10.0.0.21:34923 in memory (size: 216.0 KB, free: 308.3 MB)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.0.9:40678 in memory (size: 4.0 MB, free: 366.3 MB)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.0.21:34923 in memory (size: 4.0 MB, free: 312.3 MB)
17/11/02 09:13:07 INFO BlockManagerInfo: Removed broadcast_4_piece1 on 10.0.0.21:34923 in memory (size: 4.0 MB, free: 316.3 MB)
17/11/02 09:13:07 INFO SparkContext: Invoking stop() from shutdown hook
17/11/02 09:13:07 INFO AbstractConnector: Stopped Spark@262745b0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/11/02 09:13:07 INFO SparkUI: Stopped Spark web UI at http://10.0.0.21:4040
17/11/02 09:13:07 INFO StandaloneSchedulerBackend: Shutting down all executors
17/11/02 09:13:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
17/11/02 09:13:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/11/02 09:13:07 INFO MemoryStore: MemoryStore cleared
17/11/02 09:13:07 INFO BlockManager: BlockManager stopped
17/11/02 09:13:07 INFO BlockManagerMaster: BlockManagerMaster stopped
17/11/02 09:13:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/11/02 09:13:07 ERROR TransportResponseHandler: Still have 3 requests outstanding when connection from /10.0.0.24:49436 is closed
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@16365a27 rejected from java.util.concurrent.ThreadPoolExecutor@65201541[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 27]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:78)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:108)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:367)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:671)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:456)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@6078f82d rejected from java.util.concurrent.ThreadPoolExecutor@65201541[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 27]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:78)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:108)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:367)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:671)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:456)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
17/11/02 09:13:07 INFO SparkContext: Successfully stopped SparkContext
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@587237dd rejected from java.util.concurrent.ThreadPoolExecutor@65201541[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 27]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:78)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:108)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:278)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:220)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:367)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:671)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:456)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
17/11/02 09:13:07 INFO ShutdownHookManager: Shutdown hook called
17/11/02 09:13:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-814a4140-c62b-4dda-b6eb-1933e01cb789
